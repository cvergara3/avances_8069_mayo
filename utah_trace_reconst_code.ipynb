{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c840bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_msssim import SSIM\n",
    "\n",
    "def cargar_shot_gathers(ruta_carpeta, max_archivos=None):\n",
    "    archivos = sorted(glob.glob(os.path.join(ruta_carpeta, \"*.sgy\")))\n",
    "    if max_archivos:\n",
    "        archivos = archivos[:max_archivos]\n",
    "\n",
    "    lista_gathers = []\n",
    "    for archivo in archivos:\n",
    "        st = _read_segy(archivo, headonly=False)\n",
    "        datos = np.array([tr.data for tr in st.traces])\n",
    "        lista_gathers.append(datos)\n",
    "\n",
    "    gathers = np.stack(lista_gathers, axis=0)\n",
    "    return gathers\n",
    "    \n",
    "def submuestrear_receptores_aleatorios(gathers, porcentaje):\n",
    "    N_shots, n_receptores, n_muestras = gathers.shape\n",
    "    n_remover = int(porcentaje * n_receptores)\n",
    "\n",
    "    gathers_sub = gathers.copy()\n",
    "    idxs_removidos = []\n",
    "\n",
    "    for i in range(N_shots):\n",
    "        idx_removidos = np.sort(np.random.choice(n_receptores, n_remover, replace=False))\n",
    "        gathers_sub[i, idx_removidos, :] = 0\n",
    "        idxs_removidos.append(idx_removidos)\n",
    "\n",
    "    return gathers_sub, idxs_removidos\n",
    "\n",
    "def normalizar_por_traza(gathers_np):\n",
    "    norm = np.max(np.abs(gathers_np), axis=2, keepdims=True) + 1e-6\n",
    "    return gathers_np / norm\n",
    "\n",
    "def visualizar_comparacion(x_input, y_pred, y_true):\n",
    "    error = np.abs(y_pred - y_true)\n",
    "    vmin, vmax = -1, 1 \n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "    im0 = axs[0].imshow(x_input.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title(\"Input con trazas nulas\")\n",
    "    axs[0].set_xlabel(\"Trazas\")\n",
    "    axs[0].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im0, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im1 = axs[1].imshow(y_pred.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title(\"Predicción (U-Net)\")\n",
    "    axs[1].set_xlabel(\"Trazas\")\n",
    "    axs[1].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im2 = axs[2].imshow(y_true.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[2].set_title(\"Shot original\")\n",
    "    axs[2].set_xlabel(\"Trazas\")\n",
    "    axs[2].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im3 = axs[3].imshow(error.T, cmap='inferno', aspect='auto', origin='upper')\n",
    "    axs[3].set_title(\"Error absoluto\")\n",
    "    axs[3].set_xlabel(\"Trazas\")\n",
    "    axs[3].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im3, ax=axs[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "    fig.suptitle(\"Comparación: Entrada — Predicción — Original — Error\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calcular_metricas_globales(y_pred_tensor, y_true_tensor, x_input_tensor):\n",
    "    mse_total = []\n",
    "    psnr_total = []\n",
    "    ssim_total = []\n",
    "    snr_total = []\n",
    "\n",
    "    mse_nulas = []\n",
    "    psnr_nulas = []\n",
    "    ssim_nulas = []\n",
    "    snr_nulas = []\n",
    "\n",
    "    N = y_true_tensor.shape[0]\n",
    "\n",
    "    for i in range(N):\n",
    "        yt = y_true_tensor[i, 0].cpu().numpy()\n",
    "        xi = x_input_tensor[i, 0].cpu().numpy()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            yp = model(x_input_tensor[i:i+1].to(device)).cpu().squeeze().numpy()\n",
    "\n",
    "        # Global\n",
    "        mse = np.mean((yt - yp)**2)\n",
    "        psnr = 20 * log10(np.ptp(yt) / (np.sqrt(mse + 1e-8))) if mse > 0 else float('inf')\n",
    "        ssim_val = np.mean([ssim(yt[j], yp[j], data_range=2) for j in range(yt.shape[0])])\n",
    "        snr = 10 * np.log10(np.mean(yt**2) / (mse + 1e-8))\n",
    "\n",
    "        mse_total.append(mse)\n",
    "        psnr_total.append(psnr)\n",
    "        ssim_total.append(ssim_val)\n",
    "        snr_total.append(snr)\n",
    "\n",
    "        # Solo trazas nulas\n",
    "        idxs_nulas = np.where(np.all(xi == 0, axis=1))[0]\n",
    "        if len(idxs_nulas) > 0:\n",
    "            yt_nulas = yt[idxs_nulas]\n",
    "            yp_nulas = yp[idxs_nulas]\n",
    "\n",
    "            mse_n = np.mean((yt_nulas - yp_nulas)**2)\n",
    "            psnr_n = 20 * log10(np.ptp(yt_nulas) / (np.sqrt(mse_n + 1e-8))) if mse_n > 0 else float('inf')\n",
    "            ssim_n = np.mean([ssim(yt_nulas[j], yp_nulas[j], data_range=2) for j in range(len(idxs_nulas))])\n",
    "            snr_n = 10 * np.log10(np.mean(yt_nulas**2) / (mse_n + 1e-8))\n",
    "\n",
    "            mse_nulas.append(mse_n)\n",
    "            psnr_nulas.append(psnr_n)\n",
    "            ssim_nulas.append(ssim_n)\n",
    "            snr_nulas.append(snr_n)\n",
    "\n",
    "    return {\n",
    "        \"MSE_Global\": np.mean(mse_total),\n",
    "        \"PSNR_Global\": np.mean(psnr_total),\n",
    "        \"SSIM_Global\": np.mean(ssim_total),\n",
    "        \"SNR_Global\": np.mean(snr_total),\n",
    "        \"MSE_Nulas\": np.mean(mse_nulas),\n",
    "        \"PSNR_Nulas\": np.mean(psnr_nulas),\n",
    "        \"SSIM_Nulas\": np.mean(ssim_nulas),\n",
    "        \"SNR_Nulas\": np.mean(snr_nulas)\n",
    "    }\n",
    "\n",
    "class UNet2DFull(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet2DFull, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "\n",
    "        # Final output\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder 3\n",
    "        u3 = self.upconv3(b)\n",
    "        e3_crop = self.center_crop(e3, u3)\n",
    "        d3 = self.dec3(torch.cat([u3, e3_crop], dim=1))\n",
    "\n",
    "        # Decoder 2\n",
    "        u2 = self.upconv2(d3)\n",
    "        e2_crop = self.center_crop(e2, u2)\n",
    "        d2 = self.dec2(torch.cat([u2, e2_crop], dim=1))\n",
    "\n",
    "        # Decoder 1\n",
    "        u1 = self.upconv1(d2)\n",
    "        e1_crop = self.center_crop(e1, u1)\n",
    "        d1 = self.dec1(torch.cat([u1, e1_crop], dim=1))\n",
    "\n",
    "        # Output\n",
    "        out = self.final(d1)\n",
    "        out = torch.tanh(out)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop(enc_feature, target_feature):\n",
    "        _, _, h, w = target_feature.shape\n",
    "        _, _, H, W = enc_feature.shape\n",
    "\n",
    "        dh = (H - h) // 2\n",
    "        dw = (W - w) // 2\n",
    "\n",
    "        return enc_feature[:, :, dh:dh+h, dw:dw+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers\"\n",
    "gathers = cargar_shot_gathers(ruta, max_archivos=200)\n",
    "\n",
    "N_shots = gathers.shape[0]\n",
    "idx_train, idx_test = train_test_split(np.arange(N_shots), test_size=0.2, random_state=42)\n",
    "gathers_train = gathers[idx_train]\n",
    "gathers_test = gathers[idx_test]\n",
    "\n",
    "porcentajes = list(range(10, 100, 10))\n",
    "resultados_metricas = {}\n",
    "curvas_loss = {}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for pct in porcentajes:\n",
    "    print(f\"\\n📌 Submuestreo del {pct}%\")\n",
    "    \n",
    "    gathers_train_sub, idxs_removidos_train = submuestrear_receptores_aleatorios(gathers_train, porcentaje=pct/100)\n",
    "\n",
    "    x_np = normalizar_por_traza(gathers_train_sub)[:, :160, :2048]\n",
    "    y_np = normalizar_por_traza(gathers_train)[:, :160, :2048]\n",
    "\n",
    "    x_tensor = torch.tensor(x_np, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y_tensor = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    model = UNet2DFull().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = SSIM(data_range=1.0, size_average=True, channel=1)\n",
    "    n_epochs = 200\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x_batch, y_batch in tqdm(loader, desc=f\"Submuestreo {pct}% - Época {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = 1 - criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss_history.append(running_loss / len(loader))\n",
    "\n",
    "    curvas_loss[f\"{pct}%\"] = loss_history\n",
    "\n",
    "    gathers_test_sub, idxs_removidos_test = submuestrear_receptores_aleatorios(gathers_test, porcentaje=pct/100)\n",
    "\n",
    "    x_eval_np = normalizar_por_traza(gathers_test_sub)[:, :160, :2048]\n",
    "    y_eval_np = normalizar_por_traza(gathers_test)[:, :160, :2048]\n",
    "\n",
    "    x_eval_tensor = torch.tensor(x_eval_np, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y_eval_tensor = torch.tensor(y_eval_np, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    idx = 10\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_eval_tensor[idx:idx+1]).cpu().squeeze().numpy()\n",
    "        entrada = x_eval_tensor[idx, 0].cpu().numpy()\n",
    "        real = y_eval_tensor[idx, 0].cpu().numpy()\n",
    "        visualizar_comparacion(entrada, pred, real)\n",
    "        trazas_eliminadas = idxs_removidos_test[idx]\n",
    "\n",
    "        trazas_a_mostrar = trazas_eliminadas[:3] if len(trazas_eliminadas) >= 3 else trazas_eliminadas\n",
    "\n",
    "        tiempo = np.arange(real.shape[1])\n",
    "\n",
    "        plt.figure(figsize=(30, 4))\n",
    "        for i, traza_idx in enumerate(trazas_a_mostrar):\n",
    "            plt.subplot(1, len(trazas_a_mostrar), i+1)\n",
    "            plt.plot(tiempo, real[traza_idx], label='Real', linewidth=1.5)\n",
    "            plt.plot(tiempo, pred[traza_idx], label='Predicho', linewidth=1.5)\n",
    "            plt.title(f\"Traza eliminada #{traza_idx}\")\n",
    "            plt.xlabel(\"Tiempo\")\n",
    "            plt.ylabel(\"Amplitud\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "        plt.suptitle(f\"Comparación real vs predicho - Shot {idx}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    metricas = calcular_metricas_globales(model, y_eval_tensor, x_eval_tensor)\n",
    "    resultados_metricas[f\"{pct}\"] = metricas\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for pct, curva in curvas_loss.items():\n",
    "    plt.plot(range(1, len(curva)+1), curva, label=f\"{pct}\")\n",
    "plt.title(\"Curvas de pérdida por submuestreo\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.legend(title=\"Submuestreo\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(resultados_metricas)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
